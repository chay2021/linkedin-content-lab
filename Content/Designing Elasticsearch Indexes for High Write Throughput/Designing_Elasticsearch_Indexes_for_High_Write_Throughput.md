# Designing Elasticsearch Indexes for High Write Throughput

ğŸ‘‰ Ever had Elasticsearch indexing work flawlessly in devâ€¦ and then fall apart in production?

Nodes are green. CPU looks okay. Yet indexing slows, dashboards lag, and write rejections start appearing.

This usually isnâ€™t a hardware problem. ğŸ‘‰ Itâ€™s an index design problem â€” made long before scale arrived.

A Setup Youâ€™ve Definitely Built
App / Logs â†’ Kafka â†’ Consumer â†’ Elasticsearch â†’ Dashboards

At first: â€¢ Traffic is low â€¢ Writes are fast â€¢ Dashboards feel real-time

Confidence is high.

Then adoption grows: â€¢ 10Ã— write volume â€¢ Heap pressure spikes â€¢ Indexing backs up â€¢ Requests get rejected

And someone asks:

â€œWhy is Elasticsearch suddenly slow?â€

This is where assumptions break.

The Core Misunderstanding
Most teams assume:

â€œElasticsearch write problems mean we need bigger machines.â€

In reality: ğŸ‘‰ Most write bottlenecks come from index design choices made months earlier.

And once traffic grows, those choices become very expensive.

What We Think Helps vs What Actually Helps
What we think â€¢ More shards = more throughput â€¢ Default refresh is fine â€¢ Daily indices scale well â€¢ Replicas donâ€™t affect writes â€¢ Weâ€™ll tune later

What actually happens â€¢ Too many shards kill throughput â€¢ Refreshes steal indexing capacity â€¢ Small indices waste heap â€¢ Replicas multiply every write â€¢ Late tuning causes outages

1ï¸âƒ£ Shards: The Most Expensive Decision
Each shard is: â€¢ A Lucene index â€¢ With its own memory, segments, merges

Too many shards means: â€¢ High heap usage â€¢ More GC â€¢ Slower writes

ğŸ‘‰ Oversharding hurts more than undersharding at scale.

Rule that actually works: â€¢ Target 20â€“50 GB per shard â€¢ Fewer, larger shards > many tiny shards â€¢ You can add nodes later â€” you canâ€™t merge shards

2ï¸âƒ£ Refresh Interval: The Silent Throughput Killer
Every refresh: â€¢ Creates new segments â€¢ Triggers background work â€¢ Competes with indexing

At high write rates: ğŸ‘‰ Frequent refreshes choke throughput.

What real pipelines do: â€¢ Increase refresh to 30â€“60s â€¢ Disable refresh during bulk loads â€¢ Accept slightly stale dashboards for stability

Near-real-time â‰  every second.

3ï¸âƒ£ Replicas: Writes Are Multiplied
Replicas arenâ€™t free.

â€¢ 1 replica = 2 writes â€¢ 2 replicas = 3 writes

At scale, replicas: â€¢ Cut effective write throughput â€¢ Increase disk + network pressure

Common production pattern â€¢ Heavy ingestion â†’ replicas = 0 â€¢ After ingestion â†’ replicas increased â€¢ Kafka protects data, not ES replicas

4ï¸âƒ£ ILM: Performance Over Time
Without ILM: â€¢ Old indices stay hot â€¢ Heap usage grows â€¢ Cluster metadata explodes â€¢ Everything slowly degrades

ILM isnâ€™t about storage. ğŸ‘‰ Itâ€™s about keeping the cluster healthy as it ages.

Mature setups use: â€¢ Hot â†’ warm/cold phases â€¢ Rollover by size â€¢ Automated deletion

The Real Lesson
Elasticsearch write performance is not about: â€¢ Faster CPUs â€¢ Bigger nodes â€¢ JVM flags alone

Itâ€™s about: ğŸ‘‰ Making fewer Lucene indexes do more work.

Once traffic grows, index design becomes destiny.

ğŸ’¡ Elasticsearch doesnâ€™t fail loudly. It fails slowly â€” because of earlier decisions.

ğŸ‘‰ Which index choice hurt you the most: shards, refresh, replicas, or ILM? 

ğŸ‘‡ Share your war stories.
