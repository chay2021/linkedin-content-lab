# Dead Letter Queues (DLQ) Are Not Optional
Ever been in an incident where someone casually says:

â€œJust re-run the job.â€

â€¦and the whole room goes quiet because:

you canâ€™t replay cleanly

you donâ€™t know which records failed

and youâ€™re not even sure what got dropped

Thatâ€™s the exact moment you realize something:

âœ… Dead Letter Queues arenâ€™t a nice-to-have. Theyâ€™re what makes pipelines survivable.


A Real Day-to-Day Situation Youâ€™ve Probably Seen
Your pipeline looks simple:

Apps / APIs â†’ Kafka â†’ Consumers â†’ Elasticsearch â†’ Dashboards

Itâ€™s a normal day.

Then slowly, things start lookingâ€¦ off:

dashboards show missing records

one customer report is missing

alerts show consumer error rate went up

lag increases slightly

Nothing is fully â€œdownâ€â€¦ but something is clearly wrong.

So you open the logs.

And there it is:

MapperParsingException Field [amount] cannot be parsed as long

One bad record.

One tiny payload.

And now your whole pipeline is stuck.

At this point most teams face the same painful options:

âœ… Stop the consumer and fall behind âœ… Skip the record and lose data âœ… Retry forever and burn everything down

None of these are â€œproduction answersâ€.

This is where DLQ becomes the only sane move.


The Problem DLQ Really Solves
Pipelines rarely fail because everything is broken.

They fail because one message keeps failing repeatedly.

It could be:

schema mismatch

null in a required field

malformed JSON

bad timestamps

downstream timeouts

unexpected payload changes

And the worst part?

That one poison message can block thousands of good events behind it.

Without a DLQâ€¦ youâ€™re not engineering. Youâ€™re firefighting.


What People Assume (Until It Hurts)
Hereâ€™s the common mindset:

â€œBad data is rare.â€ â€œRetry will fix it.â€ â€œWeâ€™ll restart the consumer.â€ â€œItâ€™s only a few records, just drop them.â€

That sounds reasonableâ€¦ until the business asks:

â€œWhich records were missing?â€ â€¦and you donâ€™t have an answer.

Thatâ€™s when trust breaks.


What DLQ Actually Gives You
A DLQ is not just a storage topic.

A DLQ is your recovery lane.

Instead of this:

âŒ Fail â†’ Retry â†’ Fail â†’ Retry â†’ Block â†’ Incident â†’ Manual chaos

You get this:

âœ… Fail â†’ Retry N times â†’ Move to DLQ â†’ Pipeline continues

So your system stays alive even when data isnâ€™t perfect.


The Rule Senior Engineers Follow
A pipeline without a DLQ is not production-ready.

Because in real systems:

âœ… payloads change âœ… schemas evolve âœ… downstream services degrade âœ… â€œrareâ€ bad data shows up daily âœ… bugs happen at the worst time

DLQ is how you contain failure without taking everything down.


The DLQ Setup That Actually Works
A clean pattern looks like this:

Main Topic â†’ Consumer â†’ Success â†’ Elasticsearch  â†’ Failure â†’ Retry Topic (delay/backoff)  â†’ Still failing â†’ DLQ

What this achieves:

good events keep flowing

bad events get isolated

retries happen with control

your pipeline stays recoverable


A DLQ Without Replay Is Just a Graveyard
This part is important.

Many teams create a DLQ topicâ€¦ and never touch it again.

Thatâ€™s not resilience.

Thatâ€™s avoidance ğŸ˜„

A real DLQ strategy means:

âœ… every message stores full context âœ… failures get categorized âœ… fixes happen first âœ… replay happens safely âœ… replay is idempotent

Because the whole point of DLQ is not â€œparking problemsâ€.

Itâ€™s recovering cleanly.


The Career-Level Lesson
Junior engineers optimize for:

â€œKeep the pipeline running.â€

Senior engineers optimize for:

â€œMake the pipeline recoverable.â€

A DLQ is a design mindset:

âœ… failures must be isolatable âœ… recovery must be repeatable âœ… replay must be safe

Because production pipelines donâ€™t need luck.

They need recovery paths.


âœ… Question for you:
Do you have a DLQ and a replay planâ€¦ or just a DLQ topic quietly collecting dust?

ğŸ‘‡ Whatâ€™s the worst poison-message incident youâ€™ve seen in production?
